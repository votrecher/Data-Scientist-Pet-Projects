{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:17:55.48345Z","iopub.status.busy":"2023-09-24T16:17:55.482484Z","iopub.status.idle":"2023-09-24T16:17:55.495357Z","shell.execute_reply":"2023-09-24T16:17:55.494221Z","shell.execute_reply.started":"2023-09-24T16:17:55.4834Z"},"trusted":true},"outputs":[],"source":["import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:17:55.518481Z","iopub.status.busy":"2023-09-24T16:17:55.518019Z","iopub.status.idle":"2023-09-24T16:17:55.531851Z","shell.execute_reply":"2023-09-24T16:17:55.530537Z","shell.execute_reply.started":"2023-09-24T16:17:55.518441Z"},"trusted":true},"outputs":[],"source":["import os\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import eli5\n","from scipy.sparse import hstack\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","from matplotlib import pyplot as plt\n","from IPython.display import display_html\n","from sklearn.metrics import confusion_matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:17:55.535522Z","iopub.status.busy":"2023-09-24T16:17:55.534402Z","iopub.status.idle":"2023-09-24T16:17:55.552912Z","shell.execute_reply":"2023-09-24T16:17:55.551289Z","shell.execute_reply.started":"2023-09-24T16:17:55.535484Z"},"trusted":true},"outputs":[],"source":["PATH_TO_DATA = r'/kaggle/input/open-ml-course-linear-models-spring22/'\n","SEED = 241"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:17:55.555198Z","iopub.status.busy":"2023-09-24T16:17:55.554692Z","iopub.status.idle":"2023-09-24T16:17:55.571305Z","shell.execute_reply":"2023-09-24T16:17:55.569553Z","shell.execute_reply.started":"2023-09-24T16:17:55.555152Z"},"trusted":true},"outputs":[],"source":["def prepare_sparse_features(path_to_train, path_to_test, path_to_site_dict,\n","                           vectorizer_params):\n","    times = ['time%s' % i for i in range(1, 11)]\n","    train_df = pd.read_csv(path_to_train,\n","                       index_col='session_id', parse_dates=times)\n","    test_df = pd.read_csv(path_to_test,\n","                      index_col='session_id', parse_dates=times)\n","\n","    # Sort the data by time\n","    train_df = train_df.sort_values(by='time1')\n","    \n","    # read site -> id mapping provided by competition organizers \n","    with open(path_to_site_dict, 'rb') as f:\n","        site2id = pickle.load(f)\n","    # create an inverse id _> site mapping\n","    id2site = {v:k for (k, v) in site2id.items()}\n","    # we treat site with id 0 as \"unknown\"\n","    id2site[0] = 'unknown'\n","    \n","    # Transform data into format which can be fed into TfidfVectorizer\n","    # This time we prefer to represent sessions with site names, not site ids. \n","    # It's less efficient but thus it'll be more convenient to interpret model weights.\n","    sites = ['site%s' % i for i in range(1, 11)]\n","    train_sessions = train_df[sites].fillna(0).astype('int').apply(lambda row: \n","                                                     ' '.join([id2site[i] for i in row]), axis=1).tolist()\n","    test_sessions = test_df[sites].fillna(0).astype('int').apply(lambda row: \n","                                                     ' '.join([id2site[i] for i in row]), axis=1).tolist()\n","    # we'll tell TfidfVectorizer that we'd like to split data by whitespaces only \n","    # so that it doesn't split by dots (we wouldn't like to have 'mail.google.com' \n","    # to be split into 'mail', 'google' and 'com')\n","    vectorizer = TfidfVectorizer(**vectorizer_params)\n","    X_train = vectorizer.fit_transform(train_sessions)\n","    X_test = vectorizer.transform(test_sessions)\n","    y_train = train_df['target'].astype('int').values\n","    \n","    # we'll need site visit times for further feature engineering\n","    train_times, test_times = train_df[times], test_df[times]\n","    \n","    return X_train, X_test, y_train, vectorizer, train_times, test_times"]},{"cell_type":"markdown","metadata":{},"source":["### TF-IDF"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:17:55.574288Z","iopub.status.busy":"2023-09-24T16:17:55.573791Z","iopub.status.idle":"2023-09-24T16:18:23.612294Z","shell.execute_reply":"2023-09-24T16:18:23.610753Z","shell.execute_reply.started":"2023-09-24T16:17:55.574245Z"},"trusted":true},"outputs":[],"source":["%%time\n","X_train_sites, X_test_sites, y_train, vectorizer, train_times, test_times = prepare_sparse_features(\n","    path_to_train=os.path.join(PATH_TO_DATA, 'train.csv'),\n","    path_to_test=os.path.join(PATH_TO_DATA, 'test.csv'),\n","    path_to_site_dict=os.path.join(PATH_TO_DATA, 'site_dic.pkl'),\n","    vectorizer_params={'ngram_range': (1, 3),\n","                       'max_features': 30000, \n","                       'tokenizer': lambda s: s.split()}\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:23.615274Z","iopub.status.busy":"2023-09-24T16:18:23.61488Z","iopub.status.idle":"2023-09-24T16:18:28.346183Z","shell.execute_reply":"2023-09-24T16:18:28.345023Z","shell.execute_reply.started":"2023-09-24T16:18:23.615231Z"},"trusted":true},"outputs":[],"source":["sites_dict = pd.read_pickle(os.path.join(PATH_TO_DATA, 'site_dic.pkl'))\n","sites_dict_inv = {v: k for k, v in sites_dict.items()}\n","\n","sites_train = ['site%s' % i for i in range(1, 11)] + ['target']\n","sites_test = ['site%s' % i for i in range(1, 11)]\n","train_sites = pd.read_csv(os.path.join(PATH_TO_DATA, 'train.csv'),\n","                       index_col='session_id', parse_dates=['time%s' % i for i in range(1, 11)])\n","test_sites = pd.read_csv(os.path.join(PATH_TO_DATA, 'test.csv'),\n","                       index_col='session_id', parse_dates=['time%s' % i for i in range(1, 11)])\n","\n","train_sites = train_sites.sort_values(by='time1')\n","train_sites = train_sites[sites_train].fillna(0).astype('int')\n","test_sites = test_sites[sites_test].fillna(0).astype('int')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:28.348204Z","iopub.status.busy":"2023-09-24T16:18:28.347729Z","iopub.status.idle":"2023-09-24T16:18:28.354327Z","shell.execute_reply":"2023-09-24T16:18:28.353024Z","shell.execute_reply.started":"2023-09-24T16:18:28.348161Z"},"trusted":true},"outputs":[],"source":["features_name = []\n","corr_df = []"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:28.35863Z","iopub.status.busy":"2023-09-24T16:18:28.358118Z","iopub.status.idle":"2023-09-24T16:18:28.374027Z","shell.execute_reply":"2023-09-24T16:18:28.37314Z","shell.execute_reply.started":"2023-09-24T16:18:28.358585Z"},"trusted":true},"outputs":[],"source":["time_split = TimeSeriesSplit(n_splits=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:28.376123Z","iopub.status.busy":"2023-09-24T16:18:28.375282Z","iopub.status.idle":"2023-09-24T16:18:28.391654Z","shell.execute_reply":"2023-09-24T16:18:28.390417Z","shell.execute_reply.started":"2023-09-24T16:18:28.376091Z"},"trusted":true},"outputs":[],"source":["def write_to_submission_file(predicted_labels, out_file,\n","                             target='target', index_label=\"session_id\"):\n","    predicted_df = pd.DataFrame(predicted_labels,\n","                                index = np.arange(1, predicted_labels.shape[0] + 1),\n","                                columns=[target])\n","    predicted_df.to_csv(out_file, index_label=index_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:28.393944Z","iopub.status.busy":"2023-09-24T16:18:28.393138Z","iopub.status.idle":"2023-09-24T16:18:28.461535Z","shell.execute_reply":"2023-09-24T16:18:28.460113Z","shell.execute_reply.started":"2023-09-24T16:18:28.393898Z"},"trusted":true},"outputs":[],"source":["def train_and_predict(model, X_train, y_train, X_test, site_feature_names=vectorizer.get_feature_names(), \n","                      new_feature_names=None, cv=time_split, scoring='roc_auc',\n","                      top_n_features_to_show=30, submission_file_name='submission.csv'):\n","    \n","    \n","    cv_scores = cross_val_score(model, X_train, y_train, cv=cv, \n","                            scoring=scoring, n_jobs=4)\n","    print('CV scores', cv_scores)\n","    print('CV mean: {}, CV std: {}'.format(cv_scores.mean(), cv_scores.std()))\n","    model.fit(X_train, y_train)\n","    \n","    if new_feature_names:\n","        all_feature_names = site_feature_names + new_feature_names \n","    else: \n","        all_feature_names = site_feature_names\n","    \n","    display_html(eli5.show_weights(estimator=model, \n","                  feature_names=all_feature_names, top=top_n_features_to_show))\n","    \n","    if new_feature_names:\n","        print('New feature weights:')\n","    \n","        print(pd.DataFrame({'feature': new_feature_names, \n","                        'coef': model.coef_.flatten()[-len(new_feature_names):]}))\n","        \n","    proba = model.predict_proba(X_train)\n","    predicted = model.predict(X_train)\n","    table_confusion = confusion_matrix(y_train, predicted)\n","    test_pred = model.predict_proba(X_test)[:, 1]\n","    write_to_submission_file(test_pred, submission_file_name) \n","    \n","    return (proba, y_train, predicted, table_confusion, cv_scores)"]},{"cell_type":"markdown","metadata":{},"source":["# Time Features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:28.46359Z","iopub.status.busy":"2023-09-24T16:18:28.463122Z","iopub.status.idle":"2023-09-24T16:18:29.768002Z","shell.execute_reply":"2023-09-24T16:18:29.7667Z","shell.execute_reply.started":"2023-09-24T16:18:28.463524Z"},"trusted":true},"outputs":[],"source":["session_start_hour = train_times['time1'].apply(lambda ts: 100 * ts.hour + int(ts.minute / 10)).values"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:29.770064Z","iopub.status.busy":"2023-09-24T16:18:29.769597Z","iopub.status.idle":"2023-09-24T16:18:30.474231Z","shell.execute_reply":"2023-09-24T16:18:30.473144Z","shell.execute_reply.started":"2023-09-24T16:18:29.770032Z"},"trusted":true},"outputs":[],"source":["plt.subplots(1,  figsize = (20, 7)) \n","\n","sns.countplot(pd.DataFrame(session_start_hour[y_train == 1], columns=['time1']), x='time1')\n","plt.title(\"Alice\")\n","plt.xlabel('Session start hour')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:30.47649Z","iopub.status.busy":"2023-09-24T16:18:30.475517Z","iopub.status.idle":"2023-09-24T16:18:30.495433Z","shell.execute_reply":"2023-09-24T16:18:30.493976Z","shell.execute_reply.started":"2023-09-24T16:18:30.476453Z"},"trusted":true},"outputs":[],"source":["def add_time_features(times, X_sparse, add_feat = True):\n","    hour = times['time1'].apply(lambda t: 100 * t.hour + t.minute) / 1000\n","    morning_1 = (((hour >= 0.901) & (hour <= 0.904) | (hour >= 0.922) & (hour <= 1.209)).astype('int') * hour).values.reshape(-1, 1)\n","    morning_2 = (((hour >= 0.905) & (hour <= 0.921)).astype('int') * hour).values.reshape(-1, 1)\n","    day_1 = (((hour >= 1.210) & (hour <= 1.239)).astype('int') * hour).values.reshape(-1, 1)\n","    day_2 = (((hour >= 1.240) & (hour <= 1.335)).astype('int') * hour).values.reshape(-1, 1)\n","    day_3 = (((hour >= 1.336) & (hour <= 1.358)).astype('int') * hour).values.reshape(-1, 1)\n","    day_4 = (((hour >= 1.359) & (hour <= 1.517)).astype('int') * hour).values.reshape(-1, 1)\n","    day_5 = (((hour >= 1.518) & (hour <= 1.553)).astype('int') * hour).values.reshape(-1, 1)\n","    evening_1 = (((hour >= 1.554) & (hour <= 1.629) | (hour >= 1.705) & (hour <= 1.755)) * hour).values.reshape(-1, 1)\n","    evening_2 = ((hour >= 1.653) & (hour <= 1.704)).values.reshape(-1, 1)\n","    evening_3 = (((hour >= 1.756) & (hour <= 1.828) | (hour >= 1.626) & (hour <= 1.656)) * hour).values.reshape(-1, 1)\n","    night = (((hour >= 1.829) & (hour <= 2.359) | (hour >= 0) & (hour <= 0.900)) * hour).values.reshape(-1, 1)\n","    \n","    objects_to_hstack = [X_sparse, morning_1, morning_2, day_1, day_2, day_3, day_4, day_5, evening_1, evening_2, evening_3,night] # \n","    feature_names = ['morning_1', 'morning_2', 'day_1', 'day_2', 'day_3', 'day_4', 'day_5',  'evening_1', 'evening_2','evening_3', 'night'] #\n","    \n","    if add_feat:\n","        for i,j in zip(objects_to_hstack[1:], feature_names):\n","            feat = pd.DataFrame(pd.DataFrame(i, columns = [j]))\n","            corr_df.append(feat)\n","                            \n","    X = hstack(objects_to_hstack)\n","    return X, feature_names"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:30.501563Z","iopub.status.busy":"2023-09-24T16:18:30.501144Z","iopub.status.idle":"2023-09-24T16:18:32.018867Z","shell.execute_reply":"2023-09-24T16:18:32.017467Z","shell.execute_reply.started":"2023-09-24T16:18:30.501507Z"},"trusted":true},"outputs":[],"source":["X_train_final, new_feat_names = add_time_features(train_times, X_train_sites)\n","X_test_final, _ = add_time_features(test_times, X_test_sites, add_feat = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:32.021494Z","iopub.status.busy":"2023-09-24T16:18:32.020502Z","iopub.status.idle":"2023-09-24T16:18:32.02631Z","shell.execute_reply":"2023-09-24T16:18:32.025081Z","shell.execute_reply.started":"2023-09-24T16:18:32.021453Z"},"trusted":true},"outputs":[],"source":["features_name += new_feat_names"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:32.028931Z","iopub.status.busy":"2023-09-24T16:18:32.028427Z","iopub.status.idle":"2023-09-24T16:18:33.311204Z","shell.execute_reply":"2023-09-24T16:18:33.310172Z","shell.execute_reply.started":"2023-09-24T16:18:32.028885Z"},"trusted":true},"outputs":[],"source":["dow = train_times['time1'].apply(lambda x: x.weekday())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:33.313418Z","iopub.status.busy":"2023-09-24T16:18:33.31284Z","iopub.status.idle":"2023-09-24T16:18:33.672733Z","shell.execute_reply":"2023-09-24T16:18:33.671502Z","shell.execute_reply.started":"2023-09-24T16:18:33.313387Z"},"trusted":true},"outputs":[],"source":["plt.subplots(1, figsize = (16, 8)) \n","\n","sns.countplot(pd.DataFrame(dow[y_train == 1]), x='time1')\n","plt.title(\"Alice\")\n","plt.xlabel('Session start hour')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:33.67509Z","iopub.status.busy":"2023-09-24T16:18:33.674454Z","iopub.status.idle":"2023-09-24T16:18:33.684123Z","shell.execute_reply":"2023-09-24T16:18:33.682745Z","shell.execute_reply.started":"2023-09-24T16:18:33.675056Z"},"trusted":true},"outputs":[],"source":["def add_day_month(times, X_sparse, add_feat = True):\n","    \n","    day_of_week = times['time1'].apply(lambda t: t.weekday())\n","    day_of_week_df = pd.get_dummies(day_of_week)\n","    day_of_week_df['5_6'] = day_of_week_df[5] + day_of_week_df[6]\n","    day_of_week_df['2_3'] = day_of_week_df[2] + day_of_week_df[3]\n","    \n","    for d in (2,3,5,6):\n","        del day_of_week_df[d]\n","    \n","    day_of_week_df = day_of_week_df.rename({i: 'weekday_' + str(i) for i in day_of_week_df.columns}, axis = 1)\n","    \n","    objects_to_hstack = [X_sparse, day_of_week_df]\n","    feature_names = ['weekday_' + str(i) for i in day_of_week_df.columns]\n","    if add_feat:\n","        corr_df.append(day_of_week_df.reset_index(drop=True))\n","        \n","    X = hstack(objects_to_hstack)\n","    return X, feature_names"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:33.686131Z","iopub.status.busy":"2023-09-24T16:18:33.685748Z","iopub.status.idle":"2023-09-24T16:18:34.970794Z","shell.execute_reply":"2023-09-24T16:18:34.969581Z","shell.execute_reply.started":"2023-09-24T16:18:33.6861Z"},"trusted":true},"outputs":[],"source":["X_train_final, more_feat_names = add_day_month(train_times, X_train_final)\n","X_test_final, _ = add_day_month(test_times, X_test_final, add_feat = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:34.97414Z","iopub.status.busy":"2023-09-24T16:18:34.972909Z","iopub.status.idle":"2023-09-24T16:18:34.986064Z","shell.execute_reply":"2023-09-24T16:18:34.978528Z","shell.execute_reply.started":"2023-09-24T16:18:34.974091Z"},"trusted":true},"outputs":[],"source":["features_name += more_feat_names"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:34.990089Z","iopub.status.busy":"2023-09-24T16:18:34.98872Z","iopub.status.idle":"2023-09-24T16:18:36.132468Z","shell.execute_reply":"2023-09-24T16:18:36.131145Z","shell.execute_reply.started":"2023-09-24T16:18:34.99004Z"},"trusted":true},"outputs":[],"source":["dom = train_times['time1'].apply(lambda ts: ts.day)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:36.13493Z","iopub.status.busy":"2023-09-24T16:18:36.134512Z","iopub.status.idle":"2023-09-24T16:18:37.142366Z","shell.execute_reply":"2023-09-24T16:18:37.140976Z","shell.execute_reply.started":"2023-09-24T16:18:36.134895Z"},"trusted":true},"outputs":[],"source":["plt.subplots(1, 2, figsize = (16, 8)) \n","\n","plt.subplot(1, 2, 1)\n","sns.countplot(pd.DataFrame(dom[(y_train == 1) ]), x='time1')\n","plt.title(\"Alice\")\n","plt.xlabel('Day of month')\n","          \n","plt.subplot(1, 2, 2)\n","sns.countplot(pd.DataFrame(dom[(y_train == 0) ]), x='time1')\n","plt.title('Intruder')\n","plt.xlabel('Day of month');"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:37.144371Z","iopub.status.busy":"2023-09-24T16:18:37.143997Z","iopub.status.idle":"2023-09-24T16:18:37.156119Z","shell.execute_reply":"2023-09-24T16:18:37.154436Z","shell.execute_reply.started":"2023-09-24T16:18:37.144339Z"},"trusted":true},"outputs":[],"source":["def add_dom(times, X_sparse, add_feat = True):\n","    \n","    dom = times['time1'].apply(lambda ts: ts.day)\n","    dom_1 = (dom.isin([3,5,6,7,8,10,11,12,21,23,27,28,30])).values.reshape(-1, 1)\n","    dom_2 = (dom.isin([9,24])).values.reshape(-1, 1)\n","    dom_3 = (dom.isin([17,18,19,20,21,22,24,25,26,31])).values.reshape(-1, 1)\n","    \n","    objects_to_hstack = [X_sparse,  dom_1, dom_2, dom_3]\n","    feature_names = ['dom_1', 'dom_2', 'dom_3']   \n","    \n","    if add_feat:\n","        corr_df.append(pd.DataFrame(dom_1, columns = ['dom_1']))\n","        corr_df.append(pd.DataFrame(dom_2, columns = ['dom_2']))\n","        corr_df.append(pd.DataFrame(dom_3, columns = ['dom_3']))\n","        \n","    X = hstack(objects_to_hstack)\n","    return X, feature_names"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:37.158432Z","iopub.status.busy":"2023-09-24T16:18:37.157821Z","iopub.status.idle":"2023-09-24T16:18:38.529337Z","shell.execute_reply":"2023-09-24T16:18:38.528013Z","shell.execute_reply.started":"2023-09-24T16:18:37.158399Z"},"trusted":true},"outputs":[],"source":["X_train_final, dom_features = add_dom(train_times, X_train_final)\n","X_test_final, _ = add_dom(test_times, X_test_final, add_feat = False)\n","features_name += dom_features"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:38.531466Z","iopub.status.busy":"2023-09-24T16:18:38.531079Z","iopub.status.idle":"2023-09-24T16:18:38.537294Z","shell.execute_reply":"2023-09-24T16:18:38.535749Z","shell.execute_reply.started":"2023-09-24T16:18:38.531433Z"},"trusted":true},"outputs":[],"source":["final_model = LogisticRegression(C=20, random_state=SEED, solver='liblinear')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:18:38.539554Z","iopub.status.busy":"2023-09-24T16:18:38.538961Z","iopub.status.idle":"2023-09-24T16:19:27.0298Z","shell.execute_reply":"2023-09-24T16:19:27.028595Z","shell.execute_reply.started":"2023-09-24T16:18:38.539507Z"},"trusted":true},"outputs":[],"source":["proba, ideal, predicted, confusion_matrix, cv_scores = train_and_predict(model=final_model, X_train=X_train_final, y_train=y_train, \n","                               X_test=X_test_final, \n","                               site_feature_names=vectorizer.get_feature_names(),\n","                               new_feature_names=features_name,\n","                               cv=time_split, submission_file_name='submission.csv')"]},{"cell_type":"markdown","metadata":{},"source":["The model gives a result of 0.96878"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":108687,"sourceId":7173,"sourceType":"competition"},{"datasetId":2172031,"sourceId":3625595,"sourceType":"datasetVersion"}],"dockerImageVersionId":30558,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
